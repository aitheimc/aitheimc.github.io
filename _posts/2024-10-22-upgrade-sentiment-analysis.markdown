---
layout: post
title:  "감성분석 업그레이드"
date:   2024-10-22 00:00:00 +0900
author: Jhk
excerpt_separator: "<!--more-->"
tags:
    - 감성분석
    - Naive Bayes
    - ELECTRA
    - GPT
---

감성분석을 위한 Naive Bayes 알고리즘과 신경망 기반 언어모델(ELECTRA, GPT)의 성능을 비교한 내용입니다. Naive Bayes는 단어 빈도 기반의 간단하고 빠른 알고리즘이지만 문맥을 고려하지 못하고, 새로운 단어 처리에 제한이 있어 성능에 한계가 있습니다. 반면, ELECTRA와 GPT는 Transformer 구조를 기반으로 문맥을 이해하고, 대규모 데이터로 사전학습되어 뛰어난 성능을 보입니다. 실험 결과, ELECTRA는 Naive Bayes에 비해 8%p 높은 성능을 보였고, GPT는 추가 학습 없이도 비슷한 성능을 보였습니다. 향후 발전 방향으로는 속성기반 감성분석과 적은 데이터로도 높은 성능을 유지할 수 있는 방법을 연구할 필요성이 제시되었습니다.

<!--more-->

# 1. Naive Bayes 알고리즘
### 1.1 소개
Naive Bayes는 정답이 라벨링된 데이터를 기반으로, 단어의 출현 여부를 바탕으로 확률을 계산하고 이를 새로운 문서에 적용해 가장 가능성 높은 정답을 확률로 예측하는 알고리즘입니다.

### 1.2 장점
Naive Bayes는 확률적 분류 모델로서, 단어별 분포를 빈도 기반 확률로 계산하기 때문에 설명이 가능하며, 학습과 예측 모두에서 계산량이 적고 속도가 매우 빠릅니다.

### 1.3 단점
하지만 단순히 빈도만 사용하기 때문에 성능에 한계를 가질 수 밖에 없습니다. 왜냐하면 동음이의어나 단어의 순서와 같은 문맥이 고려되지 않기 때문입니다. 예를 들어, Naive Bayes로 계산했을 때는 '아이폰 프로는 사이즈가 너무 <U>커서 안 좋아요</U>'라는 문장과 '아이폰 미니는 사이즈가 <U>안 커서 좋아요</U>'라는 문장에서 좋다와 안 좋다는 감성의 차이가 명확하지만 순서가 고려되지 않기 때문에 확률을 계산할 때는 차이가 없습니다. 결정적으로 Naive Bayes는 학습에 제공된 데이터'만'으로 모델이 구성되기 때문에 처음 본 단어가 있을 경우, 확률이 제대로 계산되지 않기 때문에 성능이 크게 떨어지게 됩니다. 그렇기 때문에 Naive Bayes 알고리즘은 '정확하게' 정답을 라벨링한 많은 종류의 데이터가 필요합니다.

# 2. 신경망부터 ELECTRA와 GPT까지
### 2.1 설명
신경망은 입력에 대한 정답을 예측하기 위해, 내부의 가중치와 연산 과정을 반복적으로 조정하면서 최적의 함수를 학습하는 구조입니다. 이러한 신경망은 구조를 유연하게 설계할 수 있다는 특징이 있어, 다양한 형태로 발전해 왔습니다. 그중 구글이 소개한 Self-Attention은 단어간 관계에 집중하여 문맥을 효과적으로 반영하도록 설계되었으며, 동시에 Self-Attention을 핵심 매커니즘으로 다시 쌓아 만든 최종 모델인 Transformer를 소개했습니다. 이 신경망은 자연어 번역, 문서 요약, 질의응답 시스템 등 다양한 자연어처리 과제에서 뛰어난 성능을 보이며 널리 활용되고 있습니다. 이후 여러 연구자들에 의해 Transformer는 다양한 방식으로 변형되고 개선되었으며, ELECTRA, chatGPT 등 현재 다양하게 이용되고 있는 혁신적인 모델로 발전되었습니다.

ELECTRA는 로컬 환경에서 경량·효율적으로 동작하는 모델이며, ChatGPT는 원격 환경에서 대규모·추론력 중심으로 동작하는 모델로, 상반된 특성을 가지고 있습니다. 따라서 감성 분석 과제에서 두 모델의 성능을 비교하여 텍스톰의 기능을 확장하고 자 합니다.

### 2.2 ELECTRA 모델의 장단점 
ELECTRA의 기본 모델(base model)은 위키피디아와 책에서 수집한 33억개의 토큰으로 사전학습을 시켰으며 대형 모델(large-model)은 웹에서 수집한 데이터를 추가하여 330억개의 토큰으로 사전 학습시켰습니다. 330억개의 토큰은 A4용지 기준으로 500만 페이지가 되며 300장 분량의 전공서적, 약 1만 7천권에 해당하는 방대한 양의 데이터입니다.

그리고 google에서 개발한 ELECTRA는 주로 영어 데이터로 학습되었기 때문에 한국어와 중국어 모델은 기본 ELECTRA 모델에 각 언어로 구성된 데이터로 추가 학습을 시킨 모델입니다. 텍스톰에서 제공하는 한국어 모델(electra-kor-base)은 [김기영](https://github.com/kiyoungkim1) 님이 뉴스, 블로그, 댓글, 리뷰 등으로 구성된 70GB의 한국어 데이터셋으로 학습시킨 모델을 사용했습니다.

즉, 100개 ~ 1,000개의 라벨링된 학습데이터로 모델을 파인튜닝 했을 때, 모델은 100개 ~ 1,000개의 데이터만 학습한 것이 아니라 사전훈련된 방대한 양의 데이터를 기반으로 학습하는 것입니다. 이러한 사전훈련 모델의 장점으로 모델은 기본적인 감성분석 능력을 갖추고 있으며 도메인 이해에 필요한 적은 수의 데이터만으로 높은 성능을 낼 수 있습니다.

### 2.3 chatGPT API의 장단점 
ChatGPT는 대규모 데이터로 사전 학습된 모델을 원격 API를 통해 제공하는 방식으로, 뛰어난 범용성과 추론 능력을 갖추고 있습니다. 이를 감성 분석에 활용할 때 다음과 같은 장단점을 가집니다.
별도의 학습 데이터가 필요 없는 높은 초기 성능: ChatGPT는 방대한 데이터로 사전 학습되어 있어, 특정 도메인의 데이터를 추가로 학습시키지 않은 제로샷(zero-shot) 상태에서도 높은 수준의 감성 분석 성능을 보입니다. 이는 데이터 라벨링에 드는 비용과 시간을 크게 절감할 수 있는 주요 장점입니다. 또한 소수의 예시 데이터를 함께 제공하는 퓨샷(few-shot) 학습을 통해 추가적인 모델 학습 없이도 감성 분석의 정확도를 더욱 높일 수 있습니다.

하지만 범용 모델의 특성상, 특정 도메인에 맞춰 대량의 데이터로 파인튜닝된 모델보다는 성능이 다소 낮게 나타날 수 있습니다. 또한 OpenAI의 서버를 통해 작동하므로, 네트워크 상태나 외부 서비스의 정책 및 안정성에 영향을 받을 수 있습니다.

# 3. 성능 비교
본 실험은 Naive Bayes보다 발전된 Transformer 기반 ELECTRA, chatGPT를 활용하여 감성분석을 수행하고 그 차이를 Naive Bayes과 함꼐 정성적으로 비교하는 것에 있습니다.

### 3.1 데이터셋 구성
먼저 데이터셋은 박은정님이 공개하신 [영화 리뷰 데이터](https://github.com/e9t/nsmc)를 사용하였습니다. 이 데이터셋은 네이버 영화에서 리뷰와 함께 평점을 수집하여 1~4 점은 부정, 9~10점은 긍정 라벨링한 데이터입니다. 그리고 긍정과 부정의 비율이 5대5가 되도록 전체 64만 개의 리뷰에서  20만 개를 샘플링하였습니다.
다운로드 한 데이터에서 URL만 있거나 특수문자만 있는 데이터를 제거하고 전처리가 완료된 데이터셋을 무작위로 분할하여 학습용 데이터 60%, 테스트용 데이터 40%로 구성하였습니다.

### 3.2 모델 학습
Naive Bayes도 데이터의 형태나 분포의 가정에서 따라서 알고리즘이 세부적으로 구분되며, tokenizer에 따라서도 성능이 달라집니다. 테스트에 사용할 각 알고리즘의 세부 스팩은 다음과 같습니다.
- Naive Bayes : 텍스트 분류에 주로 사용되는 multinomial naive bayes를 사용하였으며, tokenizer로는 wordpiece tokenier를 사용하였습니다.
- Electra : 구글에서 개발한 기본형 모델([google/electra-base-discriminator](https://huggingface.co/google/electra-base-discriminator))에 한국어 corpus로 학습시킨 모델([kykim/electra-kor-base](https://huggingface.co/kykim/electra-kor-base))을 사용하였습니다.
- GPT : OpenAI에서 제공하는 API로 gpt-4o-mini 모델을 사용하였습니다. gpt-4o의 성능이 더 좋겠지만 빅데이터 분석 서비스를 제공하고 있기 때문에 서비스에 적용이 가능하도록 비용을 고려하여 mini 모델로 테스트하였습니다.
Naive Bayes와 ELECTRA는 구성된 데이터로 학습을 시켰으며, GPT는 범용적인 성능을 테스트 하기 위해서 zero-shot을 적용하였습니다.

### 3.3 테스트 결과

|               | Naive Bayes | ELECTRA<br>(electra-kor-base) | GPT<br>(gpt-4o-mini) |
| :-----------: | :---------: | :---------------------------: | :------------------: |
| **accuracy**  |   0.7748    |          **0.8560**           |        0.8476        |
| **precision** |   0.7753    |          **0.8573**           |        0.8571        |
|  **recall**   |   0.7748    |          **0.8560**           |        0.8476        |
| **f1 score**  |   0.7747    |          **0.8558**           |        0.8466        |

Naive Bayes는 12만 개의 데이터를 학습했음에도 동일한 데이터를 사용한 ELECTRA에 비해서 8%p나 성능이 떨어졌고 아무런 데이터를 추가 학습하지 않은 GPT에 비해서도 7%p가 떨어졌습니다. 이런 점은 문맥을 제대로 고려하지 못하는 통계적 방법론의 한계로 생각할 수 있습니다.

하지만 한 가지 의아하게 생각할 수 있습니다. 뛰어난 성능으로 모두를 놀라게 만드는 GPT가 ELECTRA보다 성능이 미세하지만 낮기 때문입니다. 그 이유는 ELECTRA는 12만 개의 데이터로 추가 학습 하면서 영화 리뷰의 문맥을 잘 이해할 수 있었기 때문입니다. 반대로 생각하면 GPT는 어떠한 추가 학습 없이도 많은 데이터를 추가 학습한 ELECTRA와 1%p 차이로 거의 비슷한 성능을 보인 것입니다.

텍스톰이라는 서비스를 운영하는 입장에서는 유저들이 일일이 라벨링 하여 데이터를 올리기는 어렵기 때문에 라벨링 없이도 높은 성능을 보이는 GPT와 유저가 업로드한 데이터로 학습하여 GPT 대비 더 높은 성능을 보이는 ELECTRA 2가지 모델을 추가하게 되었습니다.

# 4. 향후 발전 방향

### 4.1. 속성기반 감성분석의 필요성
문서 기반 감성 분석은 문서 전체를 긍정·부정·중립으로 분류하기 때문에, 하나의 문서에 여러 감정이 섞여 있는 경우 정확한 판별이 어렵습니다. 예를 들어 음식점 리뷰에서 맛과 분위기는 긍정적으로 평가하지만, 서비스와 위생은 부정적으로 평가할 수 있습니다. 각 요소별로는 감정이 뚜렷하지만, 문서 전체로 보면 긍정인지 부정인지조차 사람이 판단하기 어려울 수 있습니다.
GPT와 같이 뛰어난 모델을 사용하더라도, 이러한 문서 기반 분석 방식의 한계로 인해 결과가 부정확하다고 느껴질 수 있습니다. 따라서 문서 단위가 아니라 문장, 더 나아가 속성 단위로 감성 분석을 수행해야 보다 정확한 결과를 얻을 수 있습니다.

### 4.2. 학습 데이터 수 최적화 및 프롬프트 엔지니어링
이번 실험에서 GPT의 성능이 ELECTRA보다 낮게 나온 이유는, 학습 데이터를 제공하지 않았을 뿐 아니라 모델이 더 정확하게 응답하도록 질문과 지시문을 정교하게 설계하는 과정(프롬프트 엔지니어링)도 적용하지 않은 상태에서 평가했기 때문입니다. 정확한 감성 분석을 위해서는 분석 도메인에 맞는 데이터로 모델을 추가 학습시키는 것이 필요합니다. 또한 목적에 맞게 프롬프트를 수정·최적화하는 과정을 거치면 정확도를 더욱 향상시킬 수 있는지도 검토할 필요가 있습니다.